{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b58247f-0b15-427d-a0dc-a76a713c48ea",
   "metadata": {},
   "source": [
    "# TP 4 : Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e14853-a411-4184-ba67-3c09b2614019",
   "metadata": {},
   "source": [
    "**Avant de commencer :** Merci de bien lire le préambule et l'énoncé de ce TP. Ça vous évitera de perdre beaucoup de temps ensuite. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab662174-bc6c-42f2-9caf-e13ffd63326a",
   "metadata": {},
   "source": [
    "**Rendu :** Ce TP doit être déposé sur elearning. Le rendu doit contenir uniquement le fichier `.ipynb`. Le notebook doit être propre, le plus illustré et le plus commenté possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb54692-f4aa-4607-8788-a1c030aeb276",
   "metadata": {},
   "source": [
    "**Librairies :** Ce TP repose sur les librairies standard suivantes : \n",
    "- Numpy version used: 1.23.1\n",
    "- Matplotlib: 3.5.2\n",
    "- Pandas version used: 1.4.3\n",
    "- Scikit-learn version used: 1.1.1\n",
    "- Scipy version used: 1.7.3\n",
    "\n",
    "Pour vérifier qu'elles sont bien installées dans votre environnement de travail, lancez la cellule suivante. Elle ne doit pas renvoyer d'erreur (un `Warning` n'est en général pas trop embêtant). \n",
    "\n",
    "Pour les numéros _exacts_ de version, ce n'est pas très grave s'il y a une petite différence (par exemple `numpy 1.22` au lieu de `1.23`), mais si vous avez une trop grosse différence (par exemple `sklearn 0.23` au lieu de `sklearn 1.1`), mettez à jour votre librairie. \n",
    "\n",
    "S'il vous manque une librairie (`No module named ...`), vous pouvez l'installer \n",
    "- Soit en utilisant votre gestionnaire d'environnement (p.ex. `conda`). \n",
    "- Soit directement depuis le notebook, en faisant\n",
    "```\n",
    "!pip install nom_de_la_librairie==numero_de_la_version\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8cd512c-2638-4778-9a03-2327db394c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import distance_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3175a-a220-4896-b0e9-8758f0343088",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Partie I : Modèle plus proche voisin et jeu DIGITS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3c110-1939-4c05-a918-6070d43d31b2",
   "metadata": {},
   "source": [
    "Le jeu de données DIGITS est inspiré d'un grand classique (MNIST) des jeux de données « jouets » pour la classification. \n",
    "\n",
    "Il est constitué de 1797 observations (des images de nombres) décrits par les pixels qui le constituent sous la forme d'un tableau de longueur `64` (représentant une image `8 x 8` pixels), et réparties en 10 classes (les nombres de 0 à 9). \n",
    "\n",
    "On peut le télécharger très facilement grâce à l'API de `sklearn` via la fonction `load_digits()` dont la documentation est disponible [ici](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html). <!-- L'option `as_frame=True` permet de formater certaines données en `pandas DataFrame`. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef0d8b02-6bdd-4da7-98bd-1ca34338b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5753101f-3ac6-41ce-81bd-5be6661eada6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(digits['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32289e01-8886-427e-a6f9-0ece01978c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c660ade-823e-40dd-aef3-9025191623e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd559b33f40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits['data'][156].reshape(8,8), cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f9ea80-d978-4c0f-84be-3c2ddd05364d",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc129769-0d7d-4c39-80f4-93041bea6ea3",
   "metadata": {},
   "source": [
    "**Question 1:** Réalisez une phase exploratoire du dataset. Une fois encore, il s'agit d'une question libre ; n'hésitez pas à regarder le Chapitre 0 et le TP1 pour reprendre les bonnes habitudes sur l'exploration de jeux de données.\n",
    "\n",
    "Commentez vos observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce0de0-3701-486f-a655-25546f9b1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écrivez votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ac9fab-7ab8-41a6-9746-163727305821",
   "metadata": {},
   "source": [
    "-- Écrivez vos commentaires ici. --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e51cea0-8e82-4154-8a1b-2067112d9c86",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bca48d-e0ff-4f19-9123-ab7203e946a0",
   "metadata": {},
   "source": [
    "### Le modèle des plus proches voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9576812-e656-4b33-a892-546dfa63ff30",
   "metadata": {},
   "source": [
    "Nous allons réaliser une tâche de classification avec ce dataset. L'importance (dans un premier temps) n'est pas d'avoir un modèle performant, mais d'appliquer une bonne méthodologie et de tirer des conclusions pertinentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69fbe3e9-7c3e-4c35-92ec-c7682eefce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisissez vos deux classes ici. Par exemple 3 et 8. \n",
    "classe1 = ...\n",
    "classe2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df27133-a6f9-4d5e-b6a6-1ebd98440c02",
   "metadata": {},
   "source": [
    "**Question 2: Préparation du jeu de données.** Préparer votre jeu de données en le séparant en jeu d'entraînement et jeu de test, avec une proportion que vous aurez choisie. \n",
    "\n",
    "_Rappel:_ on peut utiliser la méthode `train_test_split` de scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18276517-9fd3-40f5-9988-6b01490c884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écrivez votre code ici. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee24373-8f92-431e-b8ad-54b47db1ae5c",
   "metadata": {},
   "source": [
    "**Modèle de plus proche voisin.** On se propose ici de tester dans un premier temps un modèle de plus proche voisin, implémenté _à la main_ (rassurez-vous, rien de compliqué). Le principe de ce modèle est le suivant : \n",
    "\n",
    "- On prend un entier $k$\n",
    "- Quand on a une observation de test $x$:\n",
    "   - On détermine les $k$ points de l'ensemble de test les plus proches de $x$\n",
    "   - On regarde le label le plus fréquent, c'est la prédiction $F(x)$ pour $x$ (en cas d'égalité, on choisira au hasard). \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba7f42e-46ac-4479-bde7-09131c337f17",
   "metadata": {},
   "source": [
    "**Question 3:** Implémenter le modèle de plus proche voisin. \n",
    "\n",
    "_Indications:_ \n",
    "- Comme vu au TP 2, on peut déterminer **toutes** les distances entre une listes de nouvelles images `new_obs` et la liste de \"référence\" `x_train` via la fonctoin `distance_matrix` de `scipy` (importée en début de TP). \n",
    "- Pour trouver les **indices** des `k` plus petites entrées de chaque **lignes** d'une matrice `A`, on peut faire `np.argsort(A, axis=1)[:,:k]`. Voir exemple dans la cellule de code ci-dessous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da420b52-1b5b-4a7f-b6b4-a1fd1313185f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La matrice aléatoire :\n",
      " [[-0.84686054 -0.43349187  0.04452494 -0.22352379  0.51145679]\n",
      " [ 1.21714977  0.27334228 -1.45788026 -1.24438783 -1.02769072]\n",
      " [-0.47861495 -1.1740434  -0.14488874 -0.11989289 -0.34286534]\n",
      " [-0.17324286  0.00861853  0.25308976 -1.24653749  1.60835969]\n",
      " [-0.10154838 -0.58893895 -0.12206315  0.34254074  1.87773971]\n",
      " [-2.24971645 -0.81811888 -0.7584066  -0.76259011 -0.11545674]\n",
      " [-0.24115697  0.58254868  0.84244988 -0.44445306  0.67512415]\n",
      " [ 0.09075909 -1.29909002  0.9940223   0.31963538  1.7339379 ]\n",
      " [ 0.84300787  0.35768345  0.52637406  0.32188733 -1.02777344]\n",
      " [-0.3425063  -1.05720324 -0.31531566 -0.14875794  2.08917646]]\n",
      "\n",
      "Indices des entrées minimales : \n",
      " [[0 1 3]\n",
      " [2 3 4]\n",
      " [1 0 4]\n",
      " [3 0 1]\n",
      " [1 2 0]\n",
      " [0 1 3]\n",
      " [3 0 1]\n",
      " [1 0 3]\n",
      " [4 3 1]\n",
      " [1 0 2]]\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randn(10, 5)  # on fabrique une matrice aléatoire de taille 10 x 5\n",
    "print(\"La matrice aléatoire :\\n\", A)   # on l'affiche\n",
    "\n",
    "Z = np.argsort(A, axis=1)[:,:3]  # on applique la fonction donneé. \n",
    "\n",
    "print(\"\\nIndices des entrées minimales : \\n\", Z)  # on affiche les indices des plus petites entrées. \n",
    "          # Par exemple, la première ligne de Z signifie \"les 3 plus proches entrées de la première ligne de A ont pour indice [machin, truc, bidule]\" \n",
    "          # (rappel : en Python, la numérotation commence à 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8984f71-5ee3-465d-a0af-57ed42c3d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifieur_plus_proche_voisin(x_test, k, x_train, y_train):\n",
    "    \"\"\"\n",
    "    :param x_test: une liste d'observations (taille N x 64) sur lesquelles ont va faire des prédictions. \n",
    "    :param k: hyper-paramètre du modèle, le nombre de voisin à considérer\n",
    "    :param x_train: le jeu de données de référence. \n",
    "    :param y_train: les labels correspondants\n",
    "    \n",
    "    :return: une liste y_pred de la même longueur que new_obs, qui indique pour chaque observation de new_obs le label prédit par votre méthode. \n",
    "    \"\"\"\n",
    "    ... # A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56635c0f-8b9d-4191-a507-cee435861670",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b85e5e1-e9d1-4da5-90db-4ec5851b47d7",
   "metadata": {},
   "source": [
    "**Question 4:** Ce modèle est-il paramétrique ? A-t-il besoin de phase d'entraînement ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11c7f4e-82f7-4ff5-8928-cd1ff44f9bfb",
   "metadata": {},
   "source": [
    "-- Écrivez votre réponse ici --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e2caa5-71eb-4f0f-b374-322a1438536b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9493c1b-9faa-42cf-84c7-6a9e95fecd10",
   "metadata": {},
   "source": [
    " Pour évaluer la performance de votre modèle sur un nouveau jeu de données `x_test` avec pour labels `y_test`, on va simplement compter le nombre de bonnes prédictions faites. \n",
    "\n",
    "**Question 5:** Implémenter la méthode `accuracy(y_pred, y_test)` qui prend en entrée une liste label prédits (typiquement la sortie de `classifieur_plus_proche_voisin`) et les vrais labels `y_test`, et qui renvoie **la proportion** de réponses correctes, c'est-à-dire\n",
    "\n",
    "$$\\frac{\\text{nombre de bonnes reponses}}{\\text{nombre de donnees dans xtest}}$$\n",
    "\n",
    "_Remarque:_ On peut aussi multiplier cette proportion par 100 pour avoir un pourcentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3c5319-70bb-4967-b950-598f402597ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_test):\n",
    "    ... # A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59d8fb4-5626-4d45-b2da-70bba65ac38a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7b36f6-1459-4e5a-9b6e-73fbadb5074e",
   "metadata": {},
   "source": [
    "**Question 6:** Évaluez la performance de votre méthode `classifieur_plus_proche_voisin` en prenant le jeu d'entraînement `x_train` comme \"nouvelles observations\" (et comme observations de références)---c'est-à-dire prendre `x_test=x_train` et `x_train=x_train`, en utilisant le paramètre `k=1`. Que remarquez vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc0353b3-1a92-4581-aac2-04c66ae91281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écrivez votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efc16bc-2996-45f8-b40d-bf044cf767a8",
   "metadata": {},
   "source": [
    "-- Écrivez votre commentaire ici --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aef9bb-ddd1-4fed-8b93-5fe1a8bb73f7",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c0be5d-abbd-460a-963c-56f37b32a035",
   "metadata": {},
   "source": [
    "**Question 7:** Évaluer la performance de votre modèle  pour différentes de valeurs de `k` (on testera **au moins** `k=1`, `k=5`, et `k=500`). Commentez le rôle du paramètre `k`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdafcbe8-1f85-4445-ac4b-b9de46842cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écrivez votre code ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3e853-9605-4a98-be2f-7b2a002396a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d88e56b8-36c7-4fe9-9fa0-7616be85b5ea",
   "metadata": {},
   "source": [
    "-- Écrivez vos commentaires ici --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ec4163-98a0-4122-995d-0f57ba4837a1",
   "metadata": {},
   "source": [
    "# Partie 2 : Classification avec Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d247aad5-7fbf-4702-b7b2-cf7e4912ceb0",
   "metadata": {},
   "source": [
    "On va maintenant travailler avec le jeu de données \"Wine\" de `sklearn` qui représente 3 types de vins (rouge, blanc, rosé ? je n'ai pas trouvé l'info sur [la doc](https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-recognition-dataset)) ; chaque vin étant représenté par 13 attributs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca33f756-7419-4c7c-9245-4d90bb92e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine_x, df_wine_y = datasets.load_wine(return_X_y=True, as_frame=True)  # version pandas\n",
    "X, y = datasets.load_wine(return_X_y=True)  # version numpy pour sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1d9888e-a803-4d7a-9706-b16c86985e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c4baa-82d7-44e5-8155-b3637efdd2af",
   "metadata": {},
   "source": [
    "**Question 1:** Mettez en place une méthodologie de classification avec `sklearn`. Vous choisirez un modèle de classification parmi ceux fournis [ici](https://scikit-learn.org/stable/supervised_learning.html) : vous pouvez prendre ceux indiquant \"classifier\" dans leur nom, ou la _logistic regression_ qui, malgré son nom, est bien une méthode de classification. \n",
    "\n",
    "Cette question est ouverte et vous devez avancer en autonomie. L'objectif **n'est pas** d'avoir une bonne performance à la fin, mais d'appliquer la méthodologie correctement, et de tirer les conclusions perinentes. Vous pouvez très bien conclure \"mon modèle _overfit_ complètement avec les paramètres que j'ai choisi, il est nul.\" ; tant que c'est bien fait, c'est ok. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340a1170-79d1-4e3b-b5ee-1a73d376a001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
